{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5689af-cb81-4020-a41c-8695f45c2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9d1ee7-48fd-4439-8d0f-9d9e86760004",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (96,96)\n",
    "IMAGE_DIR = \"train_images\"\n",
    "TARGET_COLS = [\"X4_mean\", \"X11_mean\", \"X18_mean\", \"X26_mean\", \"X50_mean\", \"X3112_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7ff23c-00cc-4a7a-80e7-d0f4d28d68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786a8af2-c702-44a2-af94-e00b44833b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de varianza explicada por los 20 componentes: 0.9253\n",
      "Total de instancias para entrenamiento: 37706\n"
     ]
    }
   ],
   "source": [
    "X_tab_raw = train_df.drop(columns=[\"id\"]).iloc[:, :-6]\n",
    "Q1 = X_tab_raw.quantile(0.25)\n",
    "Q3 = X_tab_raw.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outlier_mask = (X_tab_raw < (Q1 - 1.5 * IQR)) | (X_tab_raw > (Q3 + 1.5 * IQR))\n",
    "outlier_count = outlier_mask.sum(axis=1)\n",
    "\n",
    "mask = outlier_count <= 5\n",
    "\n",
    "X_tab_raw = X_tab_raw[mask]\n",
    "train_df = train_df[mask] \n",
    "\n",
    "y = train_df[TARGET_COLS].values\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaled = y_scaler.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_tab_raw)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"Total de varianza explicada por los 20 componentes: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"Total de instancias para entrenamiento: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99609e3-09fc-48b7-b5b3-f960a9f31bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando imágenes: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 37706/37706 [05:02<00:00, 124.50it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_image(img_id):\n",
    "    img_path = os.path.join(IMAGE_DIR, f\"{img_id}.jpg\")\n",
    "    if not os.path.exists(img_path):\n",
    "        img_path = os.path.join(IMAGE_DIR, f\"{img_id}.png\")\n",
    "    if not os.path.exists(img_path):\n",
    "        img_path = os.path.join(IMAGE_DIR, f\"{img_id}.jpeg\")\n",
    "    img = load_img(img_path, target_size=IMG_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    return preprocess_input(img)\n",
    "\n",
    "image_array = np.array([load_and_process_image(i) for i in tqdm(train_df['id'], desc=\"Cargando imágenes\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04805021-1d1b-42e7-90f6-f1956990bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_shape, tab_shape, output_dim):\n",
    "    # Imagen\n",
    "    img_input = Input(shape=img_shape)\n",
    "    base_cnn = MobileNetV2(include_top=False, weights='imagenet', input_shape=img_shape)\n",
    "    base_cnn.trainable = True  # Fine-tune\n",
    "    x_img = base_cnn(img_input)\n",
    "    x_img = GlobalAveragePooling2D()(x_img)\n",
    "\n",
    "    # Tabular\n",
    "    tab_input = Input(shape=(tab_shape,))\n",
    "    x_tab = Dense(128, activation='relu')(tab_input)\n",
    "    x_tab = Dropout(0.3)(x_tab)\n",
    "\n",
    "    # Concatenación\n",
    "    x = Concatenate()([x_img, x_tab])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(output_dim)(x)\n",
    "\n",
    "    model = Model(inputs=[img_input, tab_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "model = build_model((96, 96, 3), X_pca.shape[1], y_scaled.shape[1])\n",
    "model.compile(optimizer=Adam(1e-5), loss='mse', metrics=['root_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ab7f4e-3684-4116-b2b3-7efa807c35d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 360ms/step - loss: 2.5696 - root_mean_squared_error: 1.5478 - val_loss: 1.4981 - val_root_mean_squared_error: 1.2240\n",
      "Epoch 2/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 352ms/step - loss: 0.9828 - root_mean_squared_error: 0.9792 - val_loss: 1.3865 - val_root_mean_squared_error: 1.1775\n",
      "Epoch 3/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 350ms/step - loss: 0.8326 - root_mean_squared_error: 0.8945 - val_loss: 1.3531 - val_root_mean_squared_error: 1.1632\n",
      "Epoch 4/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 354ms/step - loss: 0.7122 - root_mean_squared_error: 0.8197 - val_loss: 1.3366 - val_root_mean_squared_error: 1.1561\n",
      "Epoch 5/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 344ms/step - loss: 0.6724 - root_mean_squared_error: 0.8123 - val_loss: 1.3279 - val_root_mean_squared_error: 1.1524\n",
      "Epoch 6/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 328ms/step - loss: 0.6449 - root_mean_squared_error: 0.7860 - val_loss: 1.3191 - val_root_mean_squared_error: 1.1485\n",
      "Epoch 7/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 331ms/step - loss: 0.5067 - root_mean_squared_error: 0.6728 - val_loss: 1.3129 - val_root_mean_squared_error: 1.1458\n",
      "Epoch 8/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 330ms/step - loss: 0.6920 - root_mean_squared_error: 0.8208 - val_loss: 1.3049 - val_root_mean_squared_error: 1.1423\n",
      "Epoch 9/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 328ms/step - loss: 0.6663 - root_mean_squared_error: 0.7985 - val_loss: 1.3006 - val_root_mean_squared_error: 1.1404\n",
      "Epoch 10/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 327ms/step - loss: 0.9140 - root_mean_squared_error: 0.9467 - val_loss: 1.2984 - val_root_mean_squared_error: 1.1395\n",
      "Epoch 11/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 332ms/step - loss: 0.7010 - root_mean_squared_error: 0.8301 - val_loss: 1.2927 - val_root_mean_squared_error: 1.1370\n",
      "Epoch 12/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 329ms/step - loss: 0.6575 - root_mean_squared_error: 0.8003 - val_loss: 1.2877 - val_root_mean_squared_error: 1.1347\n",
      "Epoch 13/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 331ms/step - loss: 0.6637 - root_mean_squared_error: 0.8021 - val_loss: 1.2830 - val_root_mean_squared_error: 1.1327\n",
      "Epoch 14/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 334ms/step - loss: 0.7212 - root_mean_squared_error: 0.8318 - val_loss: 1.2786 - val_root_mean_squared_error: 1.1307\n",
      "Epoch 15/15\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 333ms/step - loss: 0.5074 - root_mean_squared_error: 0.6888 - val_loss: 1.2750 - val_root_mean_squared_error: 1.1292\n"
     ]
    }
   ],
   "source": [
    "X_img_train, X_img_val, X_tab_train, X_tab_val, y_train, y_val = train_test_split(\n",
    "    image_array, X_pca, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    [X_img_train, X_tab_train], y_train,\n",
    "    validation_data=([X_img_val, X_tab_val], y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4414e-f8a9-4bf8-8728-00e48bd3e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score as sklearn_r2\n",
    "\n",
    "print(\"\\nR² por variable:\")\n",
    "for i, col in enumerate(TARGET_COLS):\n",
    "    # Extrae la columna i\n",
    "    y_true = y_val_real[:, i]\n",
    "    y_pred = y_pred_val_real[:, i]\n",
    "    \n",
    "    # Calcula percentiles del valor real\n",
    "    p5, p95 = np.percentile(y_true, [5, 95])\n",
    "    \n",
    "    # Máscara para conservar solo los valores dentro del rango\n",
    "    mask = (y_true >= p5) & (y_true <= p95)\n",
    "    \n",
    "    # Filtra outliers\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Calcula R² con datos filtrados\n",
    "    r2 = sklearn_r2(y_true_filtered, y_pred_filtered)\n",
    "    print(f\"{col}: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818b05b-dcf4-4d7f-af04-4887849c5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Copias para conservar datos originales\n",
    "y_val_real_filt = y_val_real.copy()\n",
    "y_pred_val_real_filt = y_pred_val_real.copy()\n",
    "\n",
    "# Filtrado por percentiles 5%-95% para cada variable\n",
    "mask_global = np.ones(len(y_val_real), dtype=bool)\n",
    "for i in range(y_val_real.shape[1]):\n",
    "    # Determinar los percentiles para los valores reales\n",
    "    p5_real, p95_real = np.percentile(y_val_real[:, i], [5, 95])\n",
    "    # Determinar los percentiles para las predicciones\n",
    "    p5_pred, p95_pred = np.percentile(y_pred_val_real[:, i], [5, 95])\n",
    "\n",
    "    # Crear una máscara booleana combinada (ambos dentro de rango)\n",
    "    mask_i = (\n",
    "        (y_val_real[:, i] >= p5_real) & (y_val_real[:, i] <= p95_real) &\n",
    "        (y_pred_val_real[:, i] >= p5_pred) & (y_pred_val_real[:, i] <= p95_pred)\n",
    "    )\n",
    "\n",
    "    # Combinar con la máscara global (conserva solo los puntos válidos en todas las columnas)\n",
    "    mask_global &= mask_i\n",
    "\n",
    "# Aplicar la máscara global\n",
    "y_val_real_filt = y_val_real[mask_global]\n",
    "y_pred_val_real_filt = y_pred_val_real[mask_global]\n",
    "\n",
    "# Graficar los datos filtrados\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.scatter(y_val_real_filt[:, i], y_pred_val_real_filt[:, i], alpha=0.3)\n",
    "    ax.plot([min(y_val_real_filt[:, i]), max(y_val_real_filt[:, i])],\n",
    "            [min(y_val_real_filt[:, i]), max(y_val_real_filt[:, i])], 'r--')\n",
    "    ax.set_title(f'{TARGET_COLS[i]}')\n",
    "    ax.set_xlabel('Real')\n",
    "    ax.set_ylabel('Predicción')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8030b80-20e1-414a-b540-7212f1ddc8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
